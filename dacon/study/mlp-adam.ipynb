{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNg3qlZE48t2TLqAh7YNdDe"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"3gydaWmJi5pe"},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch.nn.init as init \n","import torchvision \n","from torchvision import transforms, datasets\n","from sklearn.datasets import load_digits\n","from sklearn import datasets, model_selection\n","\n","from matplotlib import pyplot as plt\n","from matplotlib import cm\n","import urllib.request\n","import pandas as pd\n","\n","%matplotlib inline"]},{"cell_type":"code","source":["DEVICE = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n","EPOCHS = 7 #30\n","\n","\n","from scipy.io import loadmat\n","mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n","mnist_path = \"./mnist-original.mat\"\n","response = urllib.request.urlopen(mnist_alternative_url)\n","with open(mnist_path, \"wb\") as f:\n","    content = response.read()\n","    f.write(content)\n","mnist_raw = loadmat(mnist_path)\n","mnist = {\n","    \"data\": mnist_raw[\"data\"].T,\n","    \"target\": mnist_raw[\"label\"][0],\n","    \"COL_NAMES\": [\"label\", \"data\"],\n","    \"DESCR\": \"mldata.org dataset: mnist-original\",\n","}\n","print(\"Success!\")"],"metadata":{"id":"u4PeNrcki-D4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnist_data = mnist['data'] / 255\n","\n","pd.DataFrame(mnist_data)"],"metadata":{"id":"VWw9wXMpi_qB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.imshow(mnist_data[0].reshape(28, 28), cmap=cm.gray_r)\n","plt.show()"],"metadata":{"id":"gIWVpXWxjAkd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnist_label = mnist['target']\n","mnist_label"],"metadata":{"id":"zvMsgvAqjBc0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_size = 60000\n","test_size = 10000\n","train_X, test_X, train_Y, test_Y = model_selection.train_test_split(mnist_data,\n","                                                                    mnist_label,\n","                                                                    train_size=train_size,\n","                                                                    test_size=test_size\n","                                                                   )"],"metadata":{"id":"8OYgLRAtjCff"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","train_X = torch.from_numpy(train_X).float().to(device)\n","train_Y = torch.from_numpy(train_Y).long().to(device)\n","\n","\n","test_X = torch.from_numpy(test_X).float().to(device)\n","test_Y = torch.from_numpy(test_Y).long().to(device)\n","\n","print(train_X.shape)\n","print(train_Y.shape)"],"metadata":{"id":"kuYJdC_njDW7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = TensorDataset(train_X, train_Y)\n","train_loader = DataLoader(train, batch_size=512, shuffle=True)\n","\n","test = TensorDataset(test_X, test_Y)\n","test_loader = DataLoader(test, batch_size=512, shuffle=True)\n"],"metadata":{"id":"jGrMhbgmjJwy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MLPAdam(nn.Module):\n","  def __init__(self):\n","    super(MLPAdam, self).__init__()\n","    self.layers = nn.Sequential(\n","            nn.Linear(784, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","            nn.ReLU()\n","    )\n","    self.fc1 = nn.Linear(784, 512)\n","    self.fc2 = nn.Linear(512, 256)\n","    self.fc3 = nn.Linear(256, 128)\n","    self.fc4 = nn.Linear(128, 10)\n","    self.dropout_prob = 0.5   \n","    self.batch_norm1 = nn.BatchNorm1d(512) \n","    self.batch_norm2 = nn.BatchNorm1d(256)\n","    self.batch_norm3 = nn.BatchNorm1d(128)\n","\n","\n","\n","  def forward(self, x):\n","    x = x.view(-1, 28 * 28)\n","    x = self.fc1(x)\n","    x = self.batch_norm1(x)\n","    x = F.relu(x) \n","    x = F.dropout(x, training=self.training, p=self.dropout_prob) \n","\n","    x = self.fc2(x)\n","    x = self.batch_norm2(x)\n","    x = F.relu(x) \n","    x = F.dropout(x, training=self.training, p=self.dropout_prob) \n","\n","    x = self.fc3(x)\n","    x = self.batch_norm3(x)\n","    x = F.relu(x)\n","    x = F.dropout(x, training=self.training, p=self.dropout_prob) \n","    x = self.fc4(x)\n","    x = F.log_softmax(x, dim=1)\n","    \n","    return x\n","\n","\n"],"metadata":{"id":"FZf7gEF0sR-v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def weight_init(m):\n","    if isinstance(m, nn.Linear):\n","        init.kaiming_uniform_(m.weight.data)        # 카이밍헤 방법으로 w 초기화 하기\n","model = MLPAdam().to(DEVICE)\n","model.apply(weight_init)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"3uQZohGVLS13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(model, train_loader, optimizer, log_interval):\n","    model.train()\n","    for batch_idx, (image, label) in enumerate(train_loader):\n","        image = image.to(DEVICE)\n","        label = label.to(DEVICE)\n","        optimizer.zero_grad()\n","        output = model(image)\n","        loss = loss_fn(output, label)\n","        loss.backward()\n","        optimizer.step()"],"metadata":{"id":"2JCC7lUtP0k_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tl = []\n","def evaluate(model, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","\n","    with torch.no_grad():\n","        for image, label in test_loader:\n","            image = image.to(DEVICE)\n","            label = label.to(DEVICE)\n","            output = model(image)\n","            test_loss += loss_fn(output, label).item()\n","            prediction = output.max(1, keepdim=True)[1]\n","            correct += prediction.eq(label.view_as(prediction)).sum().item()\n","    \n","    test_loss /= len(test_loader.dataset)\n","    tl.append(test_loss)\n","    test_accuracy = 100. * correct / len(test_loader.dataset)\n","    return test_loss, test_accuracy"],"metadata":{"id":"rWZpv8r-P2dV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for Epoch in range(1, EPOCHS + 1):\n","    train(model, train_loader, optimizer, log_interval=100)\n","    test_loss, test_accuracy = evaluate(model, test_loader)\n","    print(\"[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\".format(Epoch, test_loss, test_accuracy))\n","\n","\n","plt.plot(tl, label = \"test loss\")\n","plt.title('test loss')\n","plt.xlabel('epoch')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"Y1jNk03DP4Es"},"execution_count":null,"outputs":[]}]}