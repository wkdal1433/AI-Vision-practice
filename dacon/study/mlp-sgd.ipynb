{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyNcWFTehcozfzjUXNYukvMX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Import Modules"],"metadata":{"id":"l5GIRA0GZjIV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OAnvyw-tbkvQ"},"outputs":[],"source":["import torch\n","from torch.autograd import Variable\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","from sklearn.datasets import load_digits\n","from sklearn import datasets, model_selection\n","\n","from matplotlib import pyplot as plt\n","from matplotlib import cm\n","import urllib.request\n","import pandas as pd\n","\n","%matplotlib inline"]},{"cell_type":"code","source":["from scipy.io import loadmat\n","mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n","mnist_path = \"./mnist-original.mat\"\n","response = urllib.request.urlopen(mnist_alternative_url)\n","with open(mnist_path, \"wb\") as f:\n","    content = response.read()\n","    f.write(content)\n","mnist_raw = loadmat(mnist_path)\n","mnist = {\n","    \"data\": mnist_raw[\"data\"].T,\n","    \"target\": mnist_raw[\"label\"][0],\n","    \"COL_NAMES\": [\"label\", \"data\"],\n","    \"DESCR\": \"mldata.org dataset: mnist-original\",\n","}\n","print(\"Success!\")"],"metadata":{"id":"jgCZOsUAyj_V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnist_data = mnist['data'] / 255 # mean에서만 처리를 해준건데 std도 처리를 해주면 좋지\n","\n","pd.DataFrame(mnist_data)"],"metadata":{"id":"9q_AaRIhymt_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["''' # check dataset\n","plt.imshow(mnist_data[0].reshape(28, 28), cmap=cm.gray_r)\n","plt.show()\n","'''"],"metadata":{"id":"8-MNnqP4yodH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["mnist_label = mnist['target']\n","mnist_label"],"metadata":{"id":"7pPiamFlzC7N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# len함수 같은거 이용 --> len (train_dataset)\n","train_size = 60000\n","# model selection --> val로\n","test_size = 10000\n","train_X, test_X, train_Y, test_Y = model_selection.train_test_split(mnist_data,\n","                                                                    mnist_label,\n","                                                                    train_size=train_size,\n","                                                                    test_size=test_size\n","                                                                   )"],"metadata":{"id":"2RvLdHE2zKJ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","train_X = torch.from_numpy(train_X).float().to(device)\n","train_Y = torch.from_numpy(train_Y).long().to(device)\n","\n","\n","test_X = torch.from_numpy(test_X).float().to(device)\n","test_Y = torch.from_numpy(test_Y).long().to(device)\n","\n","print(train_X.shape)\n","print(train_Y.shape)"],"metadata":{"id":"a6Z5LxodzMUq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train = TensorDataset(train_X, train_Y)\n","train_loader = DataLoader(train, batch_size=512, shuffle=True)"],"metadata":{"id":"GbwIiAhuzTQA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class MLPSGD(nn.Module):\n","  def __init__(self):\n","    super(MLPSGD, self).__init__()\n","    self.layers = nn.Sequential(\n","            nn.Linear(784, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 512),\n","            nn.ReLU(),\n","            nn.Linear(512, 10),\n","            nn.ReLU()\n","    )\n","    self.fc1 = nn.Linear(784, 512)\n","    self.fc2 = nn.Linear(512, 256)\n","    self.fc3 = nn.Linear(256, 128)\n","    self.fc4 = nn.Linear(128, 10)\n","    self.dropout_prob = 0.5   \n","    self.batch_norm1 = nn.BatchNorm1d(512) \n","    self.batch_norm2 = nn.BatchNorm1d(256)\n","    self.batch_norm3 = nn.BatchNorm1d(128)\n","\n","  def forward(self, x):\n","    x = x.view(-1, 28 * 28)\n","    x = self.fc1(x)\n","    x = self.batch_norm1(x)\n","    x = F.relu(x) \n","    x = F.dropout(x, training=self.training, p=self.dropout_prob) \n","\n","    x = self.fc2(x)\n","    x = self.batch_norm2(x)\n","    x = F.relu(x) \n","    x = F.dropout(x, training=self.training, p=self.dropout_prob) \n","\n","    x = self.fc3(x)\n","    x = self.batch_norm3(x)\n","    x = F.relu(x) # sigmoid(x)\n","    x = F.dropout(x, training=self.training, p=self.dropout_prob) \n","    x = self.fc4(x)\n","    x = F.log_softmax(x, dim=1)\n","    \n","    return x\n","\n","model = MLPSGD()\n","model.cuda()"],"metadata":{"id":"NbktoeyVzWIv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["allloss = []\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = optim.SGD(model.parameters(), lr=0.01)\n","\n","for epoch in range(1000): # 20\n","\n","  total_loss = 0\n","\n","  for train_x, train_y in train_loader:\n","\n","    train_x, train_y = Variable(train_x), Variable(train_y)\n","\n","    optimizer.zero_grad()\n","\n","    output = model(train_x)\n","\n","\n","    loss = criterion(output, train_y)\n","\n","    loss.backward()\n","\n","    optimizer.step()\n","\n","    total_loss += loss.data.item()\n","\n","\n","  if (epoch+1) % 100 == 0:\n","    print(epoch+1, total_loss)\n","    allloss.append(total_loss)\n"],"metadata":{"id":"aJOaL7Oc00FD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.plot(allloss, label = \"test accuracy\")\n","plt.title('test loss')\n","plt.xlabel('epoch')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"ippYSny-Fvfv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_x, test_y = Variable(test_X), Variable(test_Y)\n","result = torch.max(model(test_x).data, 1)[1]\n","accuracy = sum(test_y.cpu().data.numpy() == result.cpu().numpy()) / len(test_y.cpu().data.numpy())\n","\n","accuracy"],"metadata":{"id":"OZtXnIAM01BZ"},"execution_count":null,"outputs":[]}]}