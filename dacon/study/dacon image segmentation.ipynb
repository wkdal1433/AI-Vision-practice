{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNzez91lTAaAL+bXQFryO7G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## 설계 순서\n","->\n","\n","    1. pre-trained 모델 이용해서 train데이터에 대해 학습.\n","    \n","    2. 왜곡 푸는 함수 파트(반드시 평면이어야 되는건 아님)\n","   \n","    3. 다시 왜곡 사진으로 바꾸는 함수\n","    \n","    4. test에 대해 예측\n"],"metadata":{"id":"QbCMOpSjC9kC"}},{"cell_type":"code","source":["!pip install transformers\n","!pip3 install natten -f https://shi-labs.com/natten/wheels/cu118/torch2.0.0/index.html"],"metadata":{"id":"YUtkKGSAfG1R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import OneFormerProcessor, OneFormerForUniversalSegmentation\n","from PIL import Image\n","import pandas as pd\n","from tqdm import tqdm\n","import numpy as np\n","\n","import warnings\n","warnings.filterwarnings('ignore')"],"metadata":{"id":"s8pQhj3hDr6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["processor = OneFormerProcessor.from_pretrained(\"shi-labs/oneformer_cityscapes_dinat_large\")\n","model = OneFormerForUniversalSegmentation.from_pretrained(\"shi-labs/oneformer_cityscapes_dinat_large\").to('cuda')"],"metadata":{"id":"WlXsZyQPD0dp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 드라이브 연결\n"],"metadata":{"id":"cCyc2k3e1X_K"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n"],"metadata":{"id":"9YgiS4ORe5ZO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cd /content/drive/MyDrive/open"],"metadata":{"id":"0WJ4H5bmtWVp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# RLE 인코딩 함수\n","# RLE(Run-Length Encoding)은 연속적으로 반복되는 값을 압축하는 방법 중 하나입니다.\n","\n","def rle_encode(mask):\n","    # 입력된 이진 마스크를 1차원 배열로 변환합니다.\n","    pixels = mask.flatten()\n","\n","    # 배열의 시작과 끝에 0을 추가하여 RLE 알고리즘을 적용하기 위한 기본 준비를 합니다.\n","    pixels = np.concatenate([[0], pixels, [0]])\n","\n","    # 연속하지 않는 값의 인덱스를 찾아내어 압축합니다.\n","    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n","\n","    # 압축된 런 길이를 계산합니다.\n","    runs[1::2] -= runs[::2]\n","\n","    # 압축된 런을 문자열로 변환하여 반환합니다.\n","    return ' '.join(str(x) for x in runs)"],"metadata":{"id":"tOrPW4f-FYK8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## customdataset\n"],"metadata":{"id":"7-Jv2F_8zT6m"}},{"cell_type":"code","source":["# 사용자 정의 데이터셋 클래스\n","class CustomDataset(Dataset):\n","    def __init__(self, csv_file, transform=None, infer=False):\n","        # 주어진 CSV 파일을 읽어 데이터를 로드합니다.\n","        self.data = pd.read_csv(csv_file)\n","\n","        # 데이터 변환(transform) 및 추론 모드 여부(infer)를 설정합니다.\n","        self.transform = transform\n","        self.infer = infer\n","\n","    def __len__(self):\n","        # 데이터셋의 길이를 반환합니다.\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # 주어진 인덱스(idx)를 사용하여 이미지 및 마스크 파일 경로를 가져옵니다.\n","        img_path = self.data.iloc[idx, 1]\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","        if self.infer:\n","            # 추론 모드(infer)인 경우, 이미지 변환(transform)을 적용하고 이미지만 반환합니다.\n","            if self.transform:\n","                image = self.transform(image=image)['image']\n","            return image\n","\n","        mask_path = self.data.iloc[idx, 2]\n","        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","\n","        # 마스크 이미지에서 픽셀 값이 255인 부분을 12로 간주하여 변경합니다.\n","        mask[mask == 255] = 12\n","\n","        if self.transform:\n","            # 훈련 또는 검증 모드인 경우, 이미지와 마스크에 변환을 적용합니다.\n","            augmented = self.transform(image=image, mask=mask)\n","            image = augmented['image']\n","            mask = augmented['mask']\n","\n","        # 이미지와 마스크를 반환합니다.\n","        return image, mask"],"metadata":{"id":"Q4v5T8B8zOuC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 데이터 변환 파이프라인을 설정합니다. 이 파이프라인은 이미지에 대한 전처리 작업을 정의합니다.\n","#albumentations를 A로 두고 transform사용 -> albumentations는 torchvision보다 더 다양하고 빠른 모델임..\n","transform = A.Compose(\n","\n","    [\n","        # 이미지를 224x224 크기로 조정합니다.\n","        A.Resize(224, 224),\n","\n","        # 이미지를 정규화합니다. (평균과 표준편차를 사용하여 스케일링)\n","        A.Normalize(),\n","\n","        # 이미지를 PyTorch 텐서로 변환합니다.\n","        ToTensorV2()\n","    ]\n",")\n","\n"],"metadata":{"id":"klVRsEZg1C0C"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 대회에서 제공하는 train 데이터셋을 로드합니다.\n","train_dataset = CustomDataset(csv_file='train_source.csv', transform=transform)\n","\n","# 데이터로더를 설정합니다.\n","dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n","\n","# loss function과 optimizer 정의\n","criterion = torch.nn.CrossEntropyLoss()  # Cross Entropy 손실 함수를 정의합니다.\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  # Adam 옵티마이저를 정의하고 모델의 파라미터를 최적화합니다.\n","\n","# training loop\n","for epoch in range(20):  # 20 에폭 동안 학습을 반복합니다.\n","    model.train()  # 모델을 학습 모드로 설정합니다.\n","    epoch_loss = 0  # 현재 에폭의 손실을 저장할 변수를 초기화합니다.\n","\n","    for images, masks in tqdm(dataloader):\n","        images = images.float().to(device)  # 이미지 데이터를 GPU로 전송합니다.\n","        masks = masks.long().to(device)  # 마스크 데이터를 GPU로 전송합니다.\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, masks.squeeze(1))\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","\n","    print(f'Epoch {epoch+1}, Loss: {epoch_loss/len(dataloader)}')"],"metadata":{"id":"YUqH76S41CJ4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cityscapes_to_12 = {\n","    0: [6,7],\n","    1: [8],\n","    2: [11,12,13,15],\n","    3: [17,18,14],\n","    4: [1],\n","    5: [19],\n","    6: [20],\n","    7: [21],\n","    8: [23],\n","    9: [24,25],\n","    10: [],\n","    11: [26,27,28,29,30,32,33]\n","}"],"metadata":{"id":"GxSU24NeFYw-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## 추론"],"metadata":{"id":"wFQxUcDQ1pn4"}},{"cell_type":"code","source":["df = pd.read_csv('test.csv')\n","df.head()"],"metadata":{"id":"9TMgJqSpD4KI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submit = pd.read_csv('./sample_submission.csv')\n"],"metadata":{"id":"3AE93mSKFcCA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["test를 예측하는 부분(이 전에 test에 대한 처리하는 코드가 와야함)"],"metadata":{"id":"eGH8U7-rujcl"}},{"cell_type":"code","source":["result = []\n","for i in tqdm(range(len(df))):\n","    image = Image.open(df['img_path'][i])\n","    # image resize\n","    image = image.resize((960, 540))\n","\n","    semantic_inputs = processor(images=image, task_inputs=[\"semantic\"], return_tensors=\"pt\")\n","\n","    for key in semantic_inputs.keys():\n","        semantic_inputs[key] = semantic_inputs[key].to('cuda')\n","\n","    semantic_outputs = model(**semantic_inputs)\n","\n","    # pass through image_processor for postprocessing\n","    predicted_semantic_map = processor.post_process_semantic_segmentation(semantic_outputs, target_sizes=[image.size[::-1]])[0]\n","\n","    del semantic_inputs, semantic_outputs\n","    predicted_semantic_map_np = np.array(predicted_semantic_map.cpu().numpy())\n","\n","    # convert to rle\n","    for key, value in cityscapes_to_12.items():\n","        key_mask = np.isin(predicted_semantic_map_np, value)\n","        if np.sum(key_mask) > 0:\n","            mask_rle = rle_encode(key_mask)\n","            result.append(mask_rle)\n","        else:\n","            result.append(-1)"],"metadata":{"id":"MPiAedLhFkJF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["결과 중에 임의의 한장의 마스크값을 다 합쳐서 이미지를 출력하는 부분(될지 안될지는 gpu터져서 모름)"],"metadata":{"id":"NZAMe-Y5vY3q"}},{"cell_type":"code","source":["import random\n","\n","# 랜덤한 클래스 색상 지정\n","class_colors = {}\n","for class_id in range(12):\n","    # 랜덤한 RGB 값 생성\n","    color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n","    class_colors[class_id] = color\n","\n","# 모든 클래스의 마스크를 합치기 위한 빈 이미지 생성\n","merged_mask = np.zeros_like(predicted_semantic_map_np)\n","\n","# 모든 클래스에 대한 마스크를 합치고 랜덤한 색상 적용\n","for class_id, color in class_colors.items():\n","    class_mask = np.isin(predicted_semantic_map_np, [class_id]).astype(np.uint8) * 255\n","    merged_mask[class_mask > 0] = color\n","\n","# 이미지와 합친 마스크를 시각화\n","fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n","axes[0].imshow(image)\n","axes[0].set_title(\"Original Image\")\n","axes[0].axis('off')\n","axes[1].imshow(merged_mask)\n","axes[1].set_title(\"Merged Class Masks\")\n","axes[1].axis('off')\n","plt.show()"],"metadata":{"id":"LW_gCJBzezGy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submit = pd.read_csv('./sample_submission.csv')\n","submit['mask_rle'] = result\n","submit"],"metadata":{"id":"SOw3IvX6Foo-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submit.to_csv('segformer_pretrain_submit.csv', index=False)"],"metadata":{"id":"s5MQfd3dFp4T"},"execution_count":null,"outputs":[]}]}