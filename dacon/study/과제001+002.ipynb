{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyM5zvarJtOGjQJ0CePlU9aX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["-과제001-"],"metadata":{"id":"SyIBfJJvIBVp"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"flk1apU6GVGv"},"outputs":[],"source":["import os,glob\n","import pandas as pd\n","import numpy as np\n","\n","from google.colab import drive\n","drive.mount('/content/gdrive')\n","gdrive = '/content/gdrive/MyDrive/temp/datasets'\n","outputs = '/content/gdrive/MyDrive/outputs'"]},{"cell_type":"markdown","source":["ㄴ 내 구글 드라이브에 연동한 뒤 경로 설정\n"],"metadata":{"id":"oqY6VPViGsgr"}},{"cell_type":"code","source":["output_path_train = os.path.join('/content/gdrive/MyDrive/outputs', 'train')\n","if not os.path.exists(output_path_train):\n","    os.makedirs(output_path_train)\n","output_path_train = os.path.join('/content/gdrive/MyDrive/outputs', 'train_2')\n","if not os.path.exists(output_path_train):\n","    os.makedirs(output_path_train)\n","output_path_test = os.path.join('/content/gdrive/MyDrive/outputs', 'test')\n","if not os.path.exists(output_path_test):\n","     os.makedirs(output_path_test)"],"metadata":{"id":"ZpU0eoyMGsF8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ㄴ outputs/train,outputs/train_2,output/test 디렉토리를 형성"],"metadata":{"id":"9jCYvUulHNbX"}},{"cell_type":"code","source":["path_to_train_dataset_1 = os.path.join(gdrive,'mnist_train.csv')\n","path_to_train_dataset_2 = os.path.join(gdrive,'mnist_train_2.csv')\n","path_to_test_dataset = os.path.join(gdrive,'mnist_test.csv')\n","path_to_test_datasets = os.path.join(gdrive,'*.csv')"],"metadata":{"id":"CBlhSiNwHODq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ㄴ os로 파일 경로 설정"],"metadata":{"id":"HkKuaidlHQNh"}},{"cell_type":"code","source":["d1 = pd.read_csv(path_to_train_dataset_1,header=None)\n","d2 = pd.read_csv(path_to_train_dataset_2,header=None)\n","dt = pd.read_csv(path_to_test_dataset,header=None)"],"metadata":{"id":"mzsCD2NcHPka"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ㄴ d1,d2,dt로 지정해서 데이터세트 파일 불러오기"],"metadata":{"id":"XZAClJbrHTcQ"}},{"cell_type":"code","source":["d1drop = d1.drop(0,axis = 1)\n","d2drop = d2.drop(0,axis = 1)\n","dtdrop = dt.drop(0,axis = 1)"],"metadata":{"id":"4zPWDdzoHUys"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ㄴ d1,d2,dt에서 첫번째 열인 라벨 분리"],"metadata":{"id":"fzO_GdDbHW3S"}},{"cell_type":"code","source":["dtdrop"],"metadata":{"id":"TSnQPDL8HXVG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["ㄴ 잘 나오는지 테스트"],"metadata":{"id":"rfARmsKJHbK5"}},{"cell_type":"code","source":["d1label=d1[[0]]\n","d2label=d2[[0]]\n","dtlabel=dt[[0]]"],"metadata":{"id":"Gs8wDkUGHcWy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["라벨값만 따로 저장"],"metadata":{"id":"j5zk90cqHgbG"}},{"cell_type":"code","source":["for row in range(0,30000) :\n"," d1locdrop = d1drop.loc[row] #라벨이 뗀채로 한 행 추출\n"," d1labelloc = d1label.values[row]#라벨에서 value로 라벨의 하나의 값만 따로 추출\n"," d1num = d1locdrop.to_numpy() #라벨 뗀거 넘파이로\n"," d1reshape =d1num.reshape(28,28)\n"," \n"," dfd1reshape = pd.DataFrame(d1reshape)\n"," dfd1reshape.to_csv(\"/content/gdrive/MyDrive/outputs/train/\"+\"#{\"+str(d1labelloc)+\"}\"+\"-\"+\"#{\"+str(row)+\"}\"+\".csv\",index=False)\n"," #{label}-#{row_index}.csv"],"metadata":{"id":"PyDpPLdZHixU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["train 1 폴더에 저장할 이미지 파일들"],"metadata":{"id":"mgiSJbIcHlZT"}},{"cell_type":"code","source":["for row2 in range(0,30000) :\n"," d2locdrop = d2drop.loc[row2] #라벨이 뗀채로 한 행 추출\n"," d2labelloc = d2label.values[row2]#라벨만 따로 추출\n"," d2num = d2locdrop.to_numpy() #라벨 뗀거 넘파이로\n"," d2reshape =d2num.reshape(28,28)\n"," \n"," dfd2reshape = pd.DataFrame(d2reshape)\n"," dfd2reshape.to_csv(\"/content/gdrive/MyDrive/outputs/train_2/\"+\"#{\"+str(d2labelloc)+\"}\"+\"-\"+\"#{\"+str(row2)+\"}\"+\".csv\",index=False)"],"metadata":{"id":"io5K8l7cHk1q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["train2폴더에 저장"],"metadata":{"id":"6zWp4y4PHyjt"}},{"cell_type":"code","source":["for rowt in range(0,10000) :\n"," dtlocdrop = dtdrop.loc[rowt] #라벨이 뗀채로 한 행 추출\n"," dtlabelloc = dtlabel.values[rowt]#라벨만 따로 추출\n"," dtnum = dtlocdrop.to_numpy() #라벨 뗀거 넘파이로\n"," dtreshape =dtnum.reshape(28,28)\n"," \n"," dfdtreshape = pd.DataFrame(dtreshape)\n"," dfdtreshape.to_csv(\"/content/gdrive/MyDrive/outputs/test/\"+\"#{\"+str(dtlabelloc)+\"}\"+\"-\"+\"#{\"+str(rowt)+\"}\"+\".csv\",index=False)"],"metadata":{"id":"IhT6_-ztH6Dd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["test폴더에 저장"],"metadata":{"id":"WsKHk0iVH69i"}},{"cell_type":"markdown","source":["-과제002-"],"metadata":{"id":"ogjGYpVWH8Tp"}},{"cell_type":"code","source":["path_to_train_2d_datasets = os.path.join(outputs,'train','*.csv')\n","train_2d_files = glob.glob(path_to_train_2d_datasets)\n","\n","label_list = []#라벨들을 채워넣을 빈 리스트 만들기\n","\n","# We already know that the width and height of the 2D MNIST dataset is 28.\n","train = np.empty((len(train_2d_files),28,28))\n","\n","for data_idx, data_path in enumerate(train_2d_files):\n","    data = data_path[41:42]\n","    label_list.append(data)\n","    # Read the csv and replace the elements\n","    n = os.path.join(train_2d_files[data_idx])#리스트 하나하나의 파일 이름을 불러서 경로 설정\n","    d1 = pd.read_csv(n)#경로 설정한 파일을 csv로 불러오기\n","    csv_data = d1.to_numpy()#numpy배열로 바꾸기\n","    # csv_data = np.append(d1num)\n","    for i in range(28):\n","        for j in range(28):\n","            train[data_idx,i,j] = csv_data[i][j]\n","\n","# train폴더에 있는 파일들을 전부 불러서 train이라는 빈 3차원 배열에 채워넣기"],"metadata":{"id":"z3wG30_aH_Vf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(train_2d_files))"],"metadata":{"id":"KZCYH49MINBX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(label_list)"],"metadata":{"id":"WytfNeT_U4lw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["테스트"],"metadata":{"id":"_836lylXINn9"}},{"cell_type":"code","source":["#아래 코드는 라벨과 데이터를 동시에 셔플하기 위해서 하나의 셔플모델을 만드는 것\n","labelnum = np.array(label_list)#labelnum 리스트를 넘파이로 바꾸기\n","\n","s = np.arange(train.shape[0])\n","np.random.shuffle(s)\n","#만들어진 셔플모델로 라벨넘파이와 데이터 넘파이를 동일한 순서로 섞기\n","labelnum_shuffle = labelnum[s]\n","train_shuffle = train[s]"],"metadata":{"id":"OA8bfK89IOw1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 셔플된 것들을 7대2대1 비율로 나누기\n","train_x1 = labelnum_shuffle[ :21000]\n","train_y1 = train_shuffle[ :21000]\n","valid_x1 = labelnum_shuffle[21000:6000]\n","valid_y1 = train_shuffle[21000:6000]\n","test_x1  = labelnum_shuffle[27000:]\n","test_y1  = train_shuffle[27000:]"],"metadata":{"id":"iZIsSKsmIRce"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y1"],"metadata":{"id":"BUi-FkWwZzto"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(train_y1))"],"metadata":{"id":"Cg9dCRT5Z98N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["여기까지 train폴더에 있는 csv파일 3차원 배열로 바꿔준후 랜덤 셔플"],"metadata":{"id":"PRr9AoE7IV6S"}},{"cell_type":"code","source":["path_to_train_2d_datasets_2 = os.path.join(outputs,'train_2','*.csv')\n","train_2d_files_2 = glob.glob(path_to_train_2d_datasets_2)\n","\n","label_list_2 = []#라벨들을 채워넣을 빈 리스트 만들기\n","\n","# We already know that the width and height of the 2D MNIST dataset is 28.\n","train_2 = np.empty((len(train_2d_files_2),28,28))\n","\n","for data_idx_2, data_path_2 in enumerate(train_2d_files_2):\n","    \n","    data_2 = data_path_2[43:44]\n","    label_list_2.append(data_2)\n","\n","    # Read the csv and replace the elements\n","    n2 = os.path.join(train_2d_files_2[data_idx_2])#리스트 하나하나의 파일 이름을 불러서 경로 설정\n","    d2 = pd.read_csv(n2)#경로 설정한 파일을 csv로 불러오기\n","    csv_data_2 = d2.to_numpy()#numpy배열로 바꾸기\n","    # csv_data = np.append(d1num)\n","    for i2 in range(28):\n","        for j2 in range(28):\n","            train_2[data_idx_2,i2,j2] = csv_data_2[i2][j2]"],"metadata":{"id":"SpMVxHQAIijv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(train_2d_files_2))"],"metadata":{"id":"WYHUdmS9ImyA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#아래 코드는 라벨과 데이터를 동시에 셔플하기 위해서 하나의 셔플모델을 만드는 것\n","labelnum_2 = np.array(label_list_2)\n","s2 = np.arange(train_2.shape[0])\n","np.random.shuffle(s2)\n","#만들어진 셔플모델로 라벨넘파이와 데이터 넘파이를 동일한 순서로 섞기\n","labelnum_2_shuffle = labelnum_2[s2]\n","train_2_shuffle = train_2[s2]"],"metadata":{"id":"WFBtoxVZIoBQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 셔플된 것들을 7대2대1 비율로 나누기\n","train_x2 = labelnum_2_shuffle[ :21000]\n","train_y2 = train_2_shuffle[ :21000]\n","valid_x2 = labelnum_2_shuffle[21000:6000]\n","valid_y2 = train_2_shuffle[21000:6000]\n","test_x2  = labelnum_2_shuffle[27000:]\n","test_y2  = train_2_shuffle[27000:]         "],"metadata":{"id":"IzCcZqdiIqwj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(train_x2))"],"metadata":{"id":"diqNBirgIuO3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x2"],"metadata":{"id":"r710ITwRaQl5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_y2"],"metadata":{"id":"DoMPgrNPaTdg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["여기까지 train_2폴더에 있는 csv파일 3차원 배열로 바꿔준후 랜덤 셔플"],"metadata":{"id":"rv4tRKD0I0OH"}},{"cell_type":"code","source":["path_to_test_2d_datasets = os.path.join(outputs,'test','*.csv')\n","test_2d_files = glob.glob(path_to_test_2d_datasets)\n","\n","label_list_t = []#라벨들을 채워넣을 빈 리스트 만들기\n","# label_list_t = dtlabel\n","# We already know that the width and height of the 2D MNIST dataset is 28.\n","test = np.empty((len(test_2d_files),28,28))\n","\n","for data_idx_3, data_path_3 in enumerate(test_2d_files):#이 코드는 라벨들만 뽑아서 넘파이 배열로 나열한 것들, 같이 섞어주기 위해 만듦\n","\n","    data_t = data_path_3[40:41]\n","    label_list_t.append(data_t)\n","    # print(len(data_path_3))    \n","#이 코드는 라벨들만 뽑아서 넘파이 배열로 나열한 것들, 같이 섞어주기 위해 만듦\n","    # print(data_path_3)\n","    # Read the csv and replace the elements\n","    nt = os.path.join(test_2d_files[data_idx_3])#리스트 하나하나의 파일 이름을 불러서 경로 설정\n","    dt = pd.read_csv(nt)#경로 설정한 파일을 csv로 불러오기\n","    csv_data_3 = dt.to_numpy()#numpy배열로 바꾸기\n","    # csv_data = np.append(d1num)\n","    for it in range(28):\n","        for jt in range(28):\n","            test[data_idx_3,it,jt] = csv_data_3[it][jt]"],"metadata":{"id":"A4NkIw_3Ixpa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#아래 코드는 라벨과 데이터를 동시에 셔플하기 위해서 하나의 셔플모델을 만드는 것\n","labelnum_t = np.array(label_list_t)\n","st = np.arange(test.shape[0])\n","np.random.shuffle(st)\n","#만들어진 셔플모델로 라벨넘파이와 데이터 넘파이를 동일한 순서로 섞기\n","labelnum_shuffle_t = labelnum_t[st]\n","test_shuffle = test[st]"],"metadata":{"id":"NEGbyIceI39c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 셔플된 것들을 7대2대1 비율로 나누기\n","train_xt = labelnum_shuffle_t[ :7000]\n","train_yt = test_shuffle[ :7000]\n","valid_xt = labelnum_shuffle_t[7000:9000]\n","valid_yt = test_shuffle[7000:9000]\n","test_xt  = labelnum_shuffle_t[9000:]\n","test_yt  = test_shuffle[9000:]"],"metadata":{"id":"7HGjxKtUI6e-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(len(test_2d_files))"],"metadata":{"id":"IM9AWs4SI7dM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["몇개씩 나누어 졌는지 테스트"],"metadata":{"id":"BH6N3vRiI9DB"}},{"cell_type":"code","source":["train_x = np.concatenate((train_x1,train_x2,train_xt))\n","train_y = np.concatenate((train_y1,train_y2,train_yt))\n","valid_x = np.concatenate((valid_x1,valid_x1,valid_xt))\n","valid_y = np.concatenate((valid_y1,valid_y1,valid_yt))\n","test_x = np.concatenate((test_x1,test_x2,test_xt))\n","test_y = np.concatenate((test_y1,test_y2,test_yt))"],"metadata":{"id":"qnJXrmvcI-L5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["이때까지 각각 7대2대1 비율로 만들었던 넘파이 배열들을 주 목적이었던 train_x', 'train_y', 'valid_x', 'valid_y', 'test_x', 'test_y로 합치기"],"metadata":{"id":"TWohYwlkJALi"}},{"cell_type":"code","source":["np.savez('train_x',train_x)\n","np.savez('train_y',train_y)\n","np.savez('valid_x',valid_x)\n","np.savez('valid_y',valid_y)\n","np.savez('test_x',test_x)\n","np.savez('test_y',test_y)"],"metadata":{"id":"XuQ8ir0vJBFY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["npz파일로 저장"],"metadata":{"id":"hZrn6ezoJCZt"}}]}