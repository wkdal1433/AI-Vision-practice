{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"mount_file_id":"17pCpB4LgoC3ob_izSue41fXv2nRaaPig","authorship_tag":"ABX9TyP4P9VizaqTNCQS5Vm6CHdQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Import"],"metadata":{"id":"bDJJWugihCJB"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"9joiEdh0glFV"},"outputs":[],"source":["import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import cv2\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","\n","import albumentations as A\n","from albumentations.pytorch.transforms import ToTensorV2\n","import torchvision.models as models\n","\n","from tqdm.auto import tqdm\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import f1_score\n","\n","import warnings\n","warnings.filterwarnings(action='ignore') \n","from google.colab import drive\n","drive.mount('/content/gdrive')\n"]},{"cell_type":"code","source":["print(os.getcwd())"],"metadata":{"id":"o63PwOs-Rfzp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"],"metadata":{"id":"YSIx152HgniP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hyperparameter Setting"],"metadata":{"id":"_lI9x76KhGl_"}},{"cell_type":"code","source":["CFG = {\n","    'VIDEO_LENGTH':50, # 10프레임 * 5초\n","    'IMG_SIZE':128,\n","    'EPOCHS':10,\n","    'LEARNING_RATE':3e-4,\n","    'BATCH_SIZE':4,\n","    'SEED':41\n","}"],"metadata":{"id":"Ga8Vd8RogogP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Fixed RandomSeed"],"metadata":{"id":"gUpSNj90hI2T"}},{"cell_type":"code","source":["def seed_everything(seed):\n","    random.seed(seed) #random모듈을 사용한 난수 생성 씨드를 무작위로 받아옴\n","    os.environ['PYTHONHASHSEED'] = str(seed) # os.environ은 os모듈에서 환경변수를 딕셔너리 형태로 제공해주는 코드\n","    # 환경변수란 프로그램이 실행될 때 운영체제에서 설정해주는 변수 값을 의미\n","    np.random.seed(seed) \n","    torch.manual_seed(seed) # 학습시에 씨드가 고정되도록 씨드를 고정해준다. 위에서 한번 섞어주고 우리가 코드를 돌릴 때 마다 랜덤해질 수 있으므로 고정시켜줌\n","    torch.cuda.manual_seed(seed) #마찬가지로 gpu를 사용해 만들어 지는 결과들의 값을 고정해줌 \n","    torch.backends.cudnn.deterministic = True #결정된 알고리즘만 사용하도록 고정\n","    torch.backends.cudnn.benchmark = True #cudnn의 benchmark를 통해 최적의 backend 연산을 찾는 flag를 사용한다는 의미 \n","\n","seed_everything(CFG['SEED']) # Seed 고정"],"metadata":{"id":"JqoSTCAmgqQU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["씨드를 섞어주어서 난수를 생성한뒤 그에 따른 최적의 알고리즘으로 고정."],"metadata":{"id":"ardccvLzndIW"}},{"cell_type":"markdown","source":["Data Load"],"metadata":{"id":"vH7RkaT1hMsC"}},{"cell_type":"code","source":["df = pd.read_csv('./gdrive/MyDrive/open/train.csv')"],"metadata":{"id":"mZAEXmJbgrKT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train / Validation Split"],"metadata":{"id":"vDvlqqf8hOzS"}},{"cell_type":"code","source":["train, val, _, _ = train_test_split(df, df['label'], test_size=0.2, random_state=CFG['SEED'])"],"metadata":{"id":"NZs-LNhugsJB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["train, validation로 데이터셋을 나누는 단계 \n","\n","from sklearn.model_selection import train_test_split 모듈을 사용하여 val의 셋의 크기가 0.2가 되도록 나눔\n"],"metadata":{"id":"Z8jjqG5voilP"}},{"cell_type":"markdown","source":["CustomDataset"],"metadata":{"id":"R1gfTrtChRQf"}},{"cell_type":"code","source":["# 파이토치에서 데이터셋을 쉽게 다룰 수 있도록 하는 도구로서 torch.utils.data.Dataset을 상속받아서 직접 커스텀 데이터셋을 만듦\n","class CustomDataset(Dataset):\n","    def __init__(self, video_path_list, label_list):\n","        self.video_path_list = video_path_list\n","        self.label_list = label_list\n","        #생성자로 매개변수 생성\n","    def __getitem__(self, index):\n","        frames = self.get_video(self.video_path_list[index])\n","        \n","        if self.label_list is not None:\n","            label = self.label_list[index]\n","            return frames, label\n","        else:\n","            return frames\n","        #비디오와 라벨을 받아옴\n","    def __len__(self):\n","        return len(self.video_path_list)\n","        #데이터셋의 길이\n","    \n","    def get_video(self, path):\n","        frames = []\n","        cap = cv2.VideoCapture(path)\n","        for _ in range(CFG['VIDEO_LENGTH']): # 비디오 길이인 10프레임 5초만큼의 길이만큼 동영상을 나누어줌 한 영상당 50개의 이미지로 분할하여 읽어옴\n","            _, img = cap.read()\n","            img = cv2.resize(img, (CFG['IMG_SIZE'], CFG['IMG_SIZE'])) # 학습시키는 이미지의 사이즈가 동일해야 하기 때문에 사이즈 고정, 동영상은 conv하는데 오래걸리므로 적절한 사이즈 설정이 중요\n","            img = img / 255.\n","            frames.append(img)\n","        return torch.FloatTensor(np.array(frames)).permute(3, 0, 1, 2)\n","        #데이터셋에서 임의의 샘플1개를 가져오는 부분 permute로 차원의 순서를 바꾸어서 return해준다 "],"metadata":{"id":"Nq-s3KRbgs5f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = CustomDataset(train['video_path'].values, train['label'].values)\n","train_loader = DataLoader(train_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=True, num_workers=0)\n","\n","val_dataset = CustomDataset(val['video_path'].values, val['label'].values)\n","val_loader = DataLoader(val_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0)"],"metadata":{"id":"bxW5zk-3guhD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["train 데이터셋과 validation데이터셋을 불러옴"],"metadata":{"id":"nO26wVlR6U1r"}},{"cell_type":"markdown","source":["Model Define"],"metadata":{"id":"cWg7tsn8hTYk"}},{"cell_type":"code","source":["class BaseModel(nn.Module):\n","    def __init__(self, num_classes=13):\n","        super(BaseModel, self).__init__()\n","        self.feature_extract = nn.Sequential(\n","            nn.Conv3d(3, 8, (1, 3, 3)), #동영상이므로 conv3d를 해서 적용 input, output, kernel size(3차원)\n","            nn.ReLU(),\n","            nn.BatchNorm3d(8), # 마찬가지로 batchnormalization 3d \n","            nn.MaxPool3d(2),\n","            nn.Conv3d(8, 32, (1, 2, 2)),\n","            nn.ReLU(),\n","            nn.BatchNorm3d(32),\n","            nn.MaxPool3d(2),\n","            nn.Conv3d(32, 64, (1, 2, 2)),\n","            nn.ReLU(),\n","            nn.BatchNorm3d(64),\n","            nn.MaxPool3d(2),\n","            nn.Conv3d(64, 128, (1, 2, 2)),\n","            nn.ReLU(),\n","            nn.BatchNorm3d(128),\n","            nn.MaxPool3d((3, 7, 7)), \n","        )\n","        self.classifier = nn.Linear(1024, num_classes) #구분해야 하는 클래스가 13개이므로 최종 output을 13개로 설정\n","        \n","    def forward(self, x):\n","        batch_size = x.size(0)\n","        x = self.feature_extract(x)\n","        x = x.view(batch_size, -1)\n","        x = self.classifier(x)\n","        return x\n","        #위의 생성자 정의에서 정의한 함수들 forward계산 "],"metadata":{"id":"rmEoQxUsgwsK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train"],"metadata":{"id":"fVYJcDJ2hVeU"}},{"cell_type":"code","source":["def train(model, optimizer, train_loader, val_loader, scheduler, device):\n","    model.to(device) #모델을 device로 올려서 cuda로 돌림\n","    criterion = nn.CrossEntropyLoss().to(device) #loss계산도 cuda로 할거임\n","    \n","    best_val_score = 0 #오차가 0이 나올때까지 \n","    best_model = None\n","    \n","    for epoch in range(1, CFG['EPOCHS']+1): #(1~ 11) 즉 1부터 10까지\n","        model.train()\n","        train_loss = [] #loss의 보관 장소, 나중에 시각화를 하기 위함\n","        for videos, labels in tqdm(iter(train_loader)):\n","            videos = videos.to(device)\n","            labels = labels.to(device)\n","            \n","            optimizer.zero_grad() # 기울기 초기화\n","            \n","            output = model(videos) \n","            loss = criterion(output, labels)\n","            \n","            loss.backward() # back propagation이 모든 과정에서 자동화됨\n","            optimizer.step() #그 back propagation을 adam이란 우리가 설정한 optimizer로 자동 update해줌\n","            \n","            train_loss.append(loss.item())\n","                    \n","        _val_loss, _val_score = validation(model, criterion, val_loader, device)\n","        _train_loss = np.mean(train_loss)\n","        print(f'Epoch [{epoch}], Train Loss : [{_train_loss:.5f}] Val Loss : [{_val_loss:.5f}] Val F1 : [{_val_score:.5f}]') # trainloss와 val loss, val score를 소수점 5자라까지 프린트\n","        \n","        if scheduler is not None:\n","            scheduler.step(_val_score)\n","            \n","        if best_val_score < _val_score:\n","            best_val_score = _val_score\n","            best_model = model\n","    \n","    return best_model"],"metadata":{"id":"9LveXuUJgylk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validation(model, criterion, val_loader, device):\n","    model.eval()\n","    val_loss = []\n","    preds, trues = [], []\n","    \n","    with torch.no_grad(): # auto grad 엔진 끄기, 더이상 기울기 트래킹 안함\n","        for videos, labels in tqdm(iter(val_loader)):\n","            videos = videos.to(device)\n","            labels = labels.to(device)\n","            \n","            logit = model(videos)\n","            \n","            loss = criterion(logit, labels)\n","            \n","            val_loss.append(loss.item())\n","            \n","            preds += logit.argmax(1).detach().cpu().numpy().tolist() #logit tensor에 있는 최대값 인덱스를 반환하여 numpy로 바꾸기 위해 cpu에 올리고 numpy로 바꾼뒤 list화 해주는 코드\n","            trues += labels.detach().cpu().numpy().tolist() #gpu메모리에 올려져서 연산된 labels의 tensor를 numpy로 바꾸기 위해 cpu에 올리고 numpy바꾼뒤 list화 해주는 코드\n","        \n","        _val_loss = np.mean(val_loss)\n","    \n","    _val_score = f1_score(trues, preds, average='macro')\n","    return _val_loss, _val_score"],"metadata":{"id":"PmMdzykOgzsE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Run!!"],"metadata":{"id":"gFGbBUZVhYPv"}},{"cell_type":"code","source":["model = BaseModel()\n","model.eval()\n","optimizer = torch.optim.Adam(params = model.parameters(), lr = CFG[\"LEARNING_RATE\"]) #adam optimizer로 learning rate찾아주도록 함 초기 lr 3e-4\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=2,threshold_mode='abs',min_lr=1e-8, verbose=True)\n","\n","infer_model = train(model, optimizer, train_loader, val_loader, scheduler, device)"],"metadata":{"id":"ck1gsA3qg1MY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Inference"],"metadata":{"id":"xtxMVbP7ha3H"}},{"cell_type":"code","source":["test = pd.read_csv('./gdrive/MyDrive/open/test.csv')"],"metadata":{"id":"tdFafdxmg3x1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_dataset = CustomDataset(test['video_path'].values, None) #test 데이터셋을 위에 만든 CustomDataset클래스에서 불러와서 처리, 즉 동영상처리\n","test_loader = DataLoader(test_dataset, batch_size = CFG['BATCH_SIZE'], shuffle=False, num_workers=0) #불러온 테스트 데이터셋 중에 일부만 batch"],"metadata":{"id":"1JA71oZQg5FB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def inference(model, test_loader, device):\n","    model.to(device)\n","    model.eval()\n","    preds = []\n","    with torch.no_grad():\n","        for videos in tqdm(iter(test_loader)):\n","            videos = videos.to(device)\n","            \n","            logit = model(videos)\n","\n","            preds += logit.argmax(1).detach().cpu().numpy().tolist()\n","    return preds"],"metadata":{"id":"pIpcqgCYg6Gs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["preds = inference(model, test_loader, device)"],"metadata":{"id":"ZFuZNcFRg7yd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Submission -> csv로 만드는 작업"],"metadata":{"id":"xfHNVmKBhc3F"}},{"cell_type":"code","source":["submit = pd.read_csv('./gdrive/MyDrive/open/sample_submission.csv')"],"metadata":{"id":"u2okE2bjg80R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submit['label'] = preds\n","submit.head()"],"metadata":{"id":"5BFbyhoEg9iq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["submit.to_csv('./gdrive/MyDrive/open/baseline_submit.csv', index=False)"],"metadata":{"id":"kiFLHWtpg-jw"},"execution_count":null,"outputs":[]}]}